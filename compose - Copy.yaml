services:
  postgres:
    container_name: idp_postgres
    image: postgres
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - pythonapi
      - adminernet
    environment:
      POSTGRES_USER: 'idp_user'
      POSTGRES_PASSWORD: 'idp_pass'
      POSTGRES_DB: 'db_idp'
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: 50M
      restart_policy:
          condition: on-failure

  pythonapi:
    container_name: idp_python_api
    image: girnetandrei0336/idp-pythonapi:latest
    restart: always
    ports:
      - 6000:6000
    volumes:
      - ./db-microservice:/idp_db
    networks:
      - pythonapi
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: "0.2"
          memory: 50M
      restart_policy:
          condition: on-failure

  authapi:
    container_name: idp_auth_api
    image: girnetandrei0336/auth-microservice:latest
    restart: always
    ports:
      - 8888:6000
    volumes:
      - ./auth-microservice:/idp_auth
    networks:
      - pythonapi
      - adminernet
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: "0.2"
          memory: 50M
      restart_policy:
          condition: on-failure
      # keycloak:
      #   condition: service_healthy

  adminer:
    container_name: idp-adminer
    image: adminer
    restart: always
    ports:
      - 8080:8080
    depends_on: 
      postgres:
        condition: service_healthy
    networks:
      - adminernet
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: 50M
      restart_policy:
          condition: on-failure

  keycloak:
    container_name: idp-keycloak
    image: quay.io/keycloak/keycloak:23.0.1
    restart: always
    ports:
      - 8090:8080
    environment:
      KEYCLOAK_ADMIN: 'admin'
      KEYCLOAK_ADMIN_PASSWORD: 'admin'
    command:
      - start-dev
    volumes:
      - ./container-data/keycloak:/opt/keycloak/data/h2
    # healthcheck:
    #     test: ["CMD", "curl", "--head","fsS", "http://localhost:8090/health/ready"]
    #     interval: 5s
    #     timeout: 2s
    #     retries: 15
    networks:
      - pythonapi
      - adminernet
    deploy:
      resources:
        limits:
          cpus: "0.2"
          memory: 50M
      restart_policy:
          condition: on-failure
  portainer:
      image: portainer/portainer-ce:latest
      ports:
        - 9443:9443
      volumes:
          - ./container-data/portainer:/data
          - /var/run/docker.sock:/var/run/docker.sock
      restart: unless-stopped
      deploy:
        resources:
          limits:
            cpus: "0.2"
            memory: 50M
        restart_policy:
            condition: on-failure
  kong:
    image: kong:latest
    volumes:
      - ./kong:/usr/local/kong/declarative # injectarea fișierului de configurare la calea specificată
    environment:
      KONG_DATABASE: 'off' # obligatoriu, dacă se vrea modul DB-less
      KONG_DECLARATIVE_CONFIG: /usr/local/kong/declarative/kong.yml # trebuie specificat unde anume se va găsi fișierul de configurare
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001, 0.0.0.0:8444 ssl
    ports:
      - 8000:8000 # expunerea porturilor
      - 8443:8443
    deploy:
      placement:
        constraints: [node.role == manager] # constrângerea de rulare doar pe manager, pentru a nu exista conflict la nivel de volume
    networks:
      - pythonapi
      - adminernet

volumes:
  db-data:

networks:
  pythonapi:
  adminernet:
